import json
import os
from datetime import datetime, timezone
from collections import defaultdict, Counter

def process_reddit_data(input_json_path):
    """
    
    å‚æ•°:
        input_json_path (str): è¾“å…¥JSONæ–‡ä»¶è·¯å¾„ï¼ˆä¿å®ˆæ´¾/è‡ªç”±æ´¾æ•°æ®ï¼‰
    """
    # ===================== æ­¥éª¤1ï¼šè¯»å–å¹¶æ ¡éªŒæ•°æ® =====================
    if not os.path.exists(input_json_path):
        print(f"é”™è¯¯ï¼šè¾“å…¥æ–‡ä»¶ {input_json_path} ä¸å­˜åœ¨ï¼")
        return
    
    # æå–è¾“å…¥æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„å’Œåç¼€ï¼‰ï¼Œç”¨äºæ‹¼æ¥è¾“å‡ºæ–‡ä»¶å
    input_file_name = os.path.basename(input_json_path)
    input_file_prefix = os.path.splitext(input_file_name)[0]
    
    try:
        with open(input_json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if not isinstance(data, list) or len(data) == 0:
            print("é”™è¯¯ï¼šJSONæ–‡ä»¶å†…å®¹ä¸æ˜¯éç©ºæ•°ç»„æ ¼å¼ï¼")
            return
        total_posts = len(data)  # æ€»å‘å¸–æ•°ï¼ˆåˆ†æ¯ï¼‰
        print(f"æˆåŠŸè¯»å–æ•°æ®ï¼Œæ€»æ¡ç›®æ•°ï¼š{total_posts}")
    
    except json.JSONDecodeError:
        print("é”™è¯¯ï¼šJSONæ–‡ä»¶æ ¼å¼æ— æ•ˆï¼Œè¯·æ£€æŸ¥ï¼")
        return
    except Exception as e:
        print(f"è¯»å–æ•°æ®å‡ºé”™ï¼š{str(e)}")
        return

    # ===================== æ­¥éª¤2ï¼šæ—¶é—´ç»´åº¦ç»Ÿè®¡ =====================
    # åˆå§‹åŒ–æ—¶é—´ç»Ÿè®¡å­—å…¸ï¼š{å¹´ä»½: {æœˆä»½: {å‘å¸–é‡, ç‚¹èµæ•°, è¯„è®ºæ•°}}}
    time_stats = defaultdict(lambda: defaultdict(lambda: {
        "post_count": 0,
        "total_upvotes": 0,
        "total_comments": 0
    }))

    # åˆå§‹åŒ–åŸŸåç»Ÿè®¡è®¡æ•°å™¨
    domain_counter = Counter()

    # éå†æ¯æ¡æ•°æ®å¤„ç†
    for idx, item in enumerate(data):
        # å¤„ç†æ—¶é—´æˆ³
        created_utc = item.get("created_utc")
        if not isinstance(created_utc, (int, float)):
            print(f"è­¦å‘Šï¼šç¬¬ {idx+1} æ¡æ•°æ®created_utcæ— æ•ˆï¼Œè·³è¿‡")
            continue
        
        # è½¬æ¢UTCæ—¶é—´æˆ³ä¸ºå¹´æœˆæ—¥ï¼ˆå…¼å®¹ç§’çº§/æ¯«ç§’çº§ï¼‰
        try:
            ts = created_utc / 1000 if created_utc > 1e12 else created_utc
            dt = datetime.fromtimestamp(ts, tz=timezone.utc)
            year = dt.year
            month = dt.month
        except ValueError as e:
            print(f"è­¦å‘Šï¼šç¬¬ {idx+1} æ¡æ•°æ®æ—¶é—´æˆ³æ— æ•ˆï¼ˆ{created_utc}ï¼‰ï¼Œè·³è¿‡ï¼š{str(e)}")
            continue
        except Exception as e:
            print(f"è­¦å‘Šï¼šç¬¬ {idx+1} æ¡æ•°æ®æ—¶é—´è½¬æ¢å¤±è´¥ï¼Œè·³è¿‡ï¼š{str(e)}")
            continue
        
        # æå–ç‚¹èµæ•°å’Œè¯„è®ºæ•°ï¼ˆé»˜è®¤0ï¼‰
        upvotes = item.get("num_upvotes", 0)
        comments = item.get("num_comments", 0)
        upvotes = upvotes if isinstance(upvotes, (int, float)) else 0
        comments = comments if isinstance(comments, (int, float)) else 0

        # æ›´æ–°æ—¶é—´ç»Ÿè®¡
        time_stats[year][month]["post_count"] += 1
        time_stats[year][month]["total_upvotes"] += upvotes
        time_stats[year][month]["total_comments"] += comments

        # æ›´æ–°åŸŸåç»Ÿè®¡ï¼ˆè¿‡æ»¤ç©ºå€¼/æ— æ•ˆå€¼ï¼‰
        domain = item.get("url_domain", "").strip()
        if domain and domain not in ["null", "undefined"]:
            domain_counter[domain] += 1

    # ===================== æ­¥éª¤3ï¼šæ•´ç†æ—¶é—´ç»Ÿè®¡ç»“æœ =====================
    # æ ¼å¼åŒ–æ—¶é—´ç»Ÿè®¡ç»“æœï¼ˆæŒ‰å¹´æœˆå‡åºæ’åºï¼‰
    time_result = {}
    for year in sorted(time_stats.keys()):
        time_result[str(year)] = {}
        for month in sorted(time_stats[year].keys()):
            month_data = time_stats[year][month]
            time_result[str(year)][str(month)] = {
                "post_count": month_data["post_count"],
                "total_upvotes": int(month_data["total_upvotes"]),
                "total_comments": int(month_data["total_comments"]),
                "date_format_example": f"{year}-{month:02d}-01"
            }

    # ä¿å­˜æ—¶é—´ç»Ÿè®¡ç»“æœ
    time_output_path = f"time_statistics_{input_file_prefix}.json"
    with open(time_output_path, 'w', encoding='utf-8') as f:
        json.dump(time_result, f, indent=4, ensure_ascii=False)
    print(f"\nâœ… æ—¶é—´ç»Ÿè®¡ç»“æœå·²ä¿å­˜è‡³ï¼š{time_output_path}")

    # ===================== æ­¥éª¤4ï¼šæ•´ç†åŸŸåç»Ÿè®¡ç»“æœï¼ˆæ–°å¢å æ¯”é€»è¾‘ï¼‰ =====================
    # æŒ‰å‘å¸–é‡é™åºæ’åº
    sorted_domains = domain_counter.most_common()
    total_valid_domain_posts = sum(domain_counter.values())  # æœ‰æœ‰æ•ˆåŸŸåçš„å‘å¸–æ•°
    # æ€»å‘å¸–æ•°å¯èƒ½åŒ…å«æ— åŸŸåçš„æƒ…å†µï¼Œå æ¯”åˆ†æ¯ç”¨æ€»å‘å¸–æ•°total_posts
    total_posts_denominator = total_posts

    # -------------------- 4.1 Top5 åŸŸåç»Ÿè®¡ï¼ˆå«å æ¯”ï¼‰ --------------------
    top5_domains = []
    top5_total = 0
    for d, c in sorted_domains[:5]:
        ratio = round((c / total_posts_denominator) * 100, 4)  # ä¿ç•™4ä½å°æ•°
        top5_domains.append({
            "domain": d,
            "post_count": c,
            "post_ratio(%)": ratio  # å æ€»å‘å¸–æ•°çš„ç™¾åˆ†æ¯”
        })
        top5_total += c

    # è®¡ç®—Top5ä¹‹å¤–çš„åŸŸåç»Ÿè®¡
    other_than_top5_count = total_valid_domain_posts - top5_total
    other_than_top5_ratio = round((other_than_top5_count / total_posts_denominator) * 100, 4)
    # è¡¥å……æ— åŸŸåçš„å‘å¸–æ•°å’Œå æ¯”ï¼ˆæ€»å‘å¸–æ•° - æœ‰æœ‰æ•ˆåŸŸåçš„å‘å¸–æ•°ï¼‰
    no_domain_count = total_posts_denominator - total_valid_domain_posts
    no_domain_ratio = round((no_domain_count / total_posts_denominator) * 100, 4)

    top5_result = {
        "top5_domains": top5_domains,
        "top5_total_posts": top5_total,
        "top5_total_ratio(%)": round((top5_total / total_posts_denominator) * 100, 4),
        "other_than_top5": {
            "post_count": other_than_top5_count,
            "post_ratio(%)": other_than_top5_ratio
        },
        "no_domain_posts": {  # æ— æœ‰æ•ˆåŸŸåçš„å‘å¸–æ•°
            "post_count": no_domain_count,
            "post_ratio(%)": no_domain_ratio
        },
        "total_posts": total_posts_denominator,  # æ€»å‘å¸–æ•°ï¼ˆåˆ†æ¯ï¼‰
        "total_valid_domain_posts": total_valid_domain_posts  # æœ‰æœ‰æ•ˆåŸŸåçš„å‘å¸–æ•°
    }

    # ä¿å­˜Top5åŸŸåç»“æœï¼ˆå«å æ¯”ï¼‰
    top5_path = f"top5_domains_{input_file_prefix}.json"
    with open(top5_path, 'w', encoding='utf-8') as f:
        json.dump(top5_result, f, indent=4, ensure_ascii=False)
    print(f"âœ… Top5 åŸŸåç»Ÿè®¡ï¼ˆå«å æ¯”ï¼‰å·²ä¿å­˜è‡³ï¼š{top5_path}")

    # -------------------- 4.2 Top10 åŸŸåç»Ÿè®¡ï¼ˆå«å æ¯”ï¼‰ --------------------
    top10_domains = []
    top10_total = 0
    for d, c in sorted_domains[:10]:
        ratio = round((c / total_posts_denominator) * 100, 4)
        top10_domains.append({
            "domain": d,
            "post_count": c,
            "post_ratio(%)": ratio
        })
        top10_total += c

    # è®¡ç®—Top10ä¹‹å¤–çš„åŸŸåç»Ÿè®¡
    other_than_top10_count = total_valid_domain_posts - top10_total
    other_than_top10_ratio = round((other_than_top10_count / total_posts_denominator) * 100, 4)

    top10_result = {
        "top10_domains": top10_domains,
        "top10_total_posts": top10_total,
        "top10_total_ratio(%)": round((top10_total / total_posts_denominator) * 100, 4),
        "other_than_top10": {
            "post_count": other_than_top10_count,
            "post_ratio(%)": other_than_top10_ratio
        },
        "no_domain_posts": {
            "post_count": no_domain_count,
            "post_ratio(%)": no_domain_ratio
        },
        "total_posts": total_posts_denominator,
        "total_valid_domain_posts": total_valid_domain_posts
    }

    # ä¿å­˜Top10åŸŸåç»“æœï¼ˆå«å æ¯”ï¼‰
    top10_path = f"top10_domains_{input_file_prefix}.json"
    with open(top10_path, 'w', encoding='utf-8') as f:
        json.dump(top10_result, f, indent=4, ensure_ascii=False)
    print(f"âœ… Top10 åŸŸåç»Ÿè®¡ï¼ˆå«å æ¯”ï¼‰å·²ä¿å­˜è‡³ï¼š{top10_path}")

    # ===================== è¾“å‡ºç»Ÿè®¡æ‘˜è¦ =====================
    print("\nğŸ“Š ç»Ÿè®¡æ‘˜è¦ï¼š")
    if time_stats:
        print(f"- æ—¶é—´è¦†ç›–èŒƒå›´ï¼š{min(time_stats.keys())} ~ {max(time_stats.keys())}")
    print(f"- æ€»å‘å¸–æ•°ï¼š{total_posts_denominator}")
    print(f"- æœ‰æœ‰æ•ˆåŸŸåçš„å‘å¸–æ•°ï¼š{total_valid_domain_posts}ï¼ˆå æ¯” {round((total_valid_domain_posts/total_posts_denominator)*100,4)}%ï¼‰")
    print(f"- æ— æœ‰æ•ˆåŸŸåçš„å‘å¸–æ•°ï¼š{no_domain_count}ï¼ˆå æ¯” {no_domain_ratio}%ï¼‰")
    print(f"- å‘å¸–é‡æœ€é«˜åŸŸåï¼š{sorted_domains[0][0]}ï¼ˆ{sorted_domains[0][1]} æ¡ï¼Œå æ¯” {round((sorted_domains[0][1]/total_posts_denominator)*100,4)}%ï¼‰")

# ===================== ä¸»ç¨‹åºå…¥å£ =====================
if __name__ == "__main__":
    INPUT_FILE = "conservative.json"
    
    # æ‰§è¡Œæ•°æ®å¤„ç†
    process_reddit_data(INPUT_FILE)